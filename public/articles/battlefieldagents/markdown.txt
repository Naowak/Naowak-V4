# BattleFieldAgents : GPT-4 pour contr√¥ler des agents intelligents

Dans le monde de l'intelligence artificielle (IA), les mod√®les de langage comme [GPT-4 d'OpenAI](https://openai.com/gpt-4) ont ouvert de nouvelles portes pour la simulation d'agents intelligents. Dans cet article, nous parlerons de mon dernier projet en date : "BattleFieldAgents", qui utilise [GPT-4](https://openai.com/gpt-4) pour contr√¥ler des agents dans un jeu vid√©o de strat√©gie. Nous discuterons de la conception du jeu, des d√©fis rencontr√©s, et de la mani√®re dont l'IA a √©t√© int√©gr√©e pour cr√©er une exp√©rience de jeu unique.

![BattleFieldAgents : example d'une partie en vid√©o](https://youtu.be/W-KyDJx34Qg)

#### Pr√©sentation du projet "BattleFieldAgents"

"BattleFieldAgents" est un projet de jeu vid√©o strat√©gique qui utilise le mod√®le de langage [GPT-4 d'OpenAI](https://openai.com/gpt-4) pour contr√¥ler des agents dans le jeu. Les agents sont con√ßus pour prendre des d√©cisions strat√©giques en fonction de leur environnement et expliquer leurs raisonnements derri√®re leurs actions. L'objectif du projet est de permettre √† ces agents de communiquer en langage naturel (ici en anglais), de se partager des informations importantes, et de coordonner leurs actions pour atteindre un objectif commun.

Le jeu est un champ de bataille dispos√© sur une grille 2D et se compose de deux √©quipes : "rouge" et "bleu", chacune ayant plusieurs agents (100 pdv). Chaque √©quipe poss√®de une cible (150 pdv) qu'elle doit prot√©ger tout en essayant de d√©truire la cible ennemie. Sur le champ de bataille, il y a √©galement des obstacles positionn√©s al√©atoirement qui obstruent le champ de vue des agents et leurs d√©placements. Les agents peuvent tirer sur n'importe quel ennemi (agent ou cible) qui est dans leur champ de vue. Lorsqu'une balle touche un agent ou une cible, leurs points de vie sont r√©duits de 25. Si les points de vie d'un agent atteignent z√©ro, il est retir√© du jeu. Si les points de vie d'une cible atteignent z√©ro, le jeu est gagn√© par l'√©quipe adverse. Si tous les agents d'une √©quipe sont retir√©s du jeu, l'√©quipe adverse gagne.

Chaque agent doit r√©aliser 3 actions par tour, et poss√®de les informations suivantes : 
- sa position actuelle 
- ses points de vie
- ce qu'il voit (agents, cibles, obstacles) et leurs coordonn√©es
- les messages qu'il a re√ßu de ses co√©quipiers
- un historique de ses actions pr√©c√©dentes
- une m√©moire des derni√®res positions observ√©es pour chaque agent et cible  

Ils utilisent ces informations pour d√©cider de ce qu'ils vont faire, c'est √† dire se d√©placer de 1 √† 3 cases, attaquer un adversaire en vu, ou communiquer avec un co√©quipier en vu.  



#### Vulgarisation du fonctionnement du projet


Pour comprendre comment "BattleFieldAgents" fonctionne, il est utile de le visualiser comme un cycle d'interaction entre le jeu et [GPT-4](https://openai.com/gpt-4). Voici un sch√©ma simplifi√© de ce cycle :

![Workflow](/battlefieldagents/workflow.png)

1. Le jeu envoie l'√©tat actuel du jeu √† l'API Python. Cet √©tat comprend des informations sur la position des agents, leur vie, les obstacles, etc.
2. L'API Python g√©n√®re un prompt bas√© sur cet √©tat et l'envoie √† GPT-4.
3. GPT-4 g√©n√®re une action bas√©e sur le prompt et la renvoie √† l'API Python.
4. L'API Python traduit cette action en une commande que le jeu peut comprendre et l'envoie au jeu.
5. Le jeu ex√©cute la commande, met √† jour l'√©tat du jeu, et le cycle recommence.

Ce cycle se r√©p√®te pour chaque action et pour chaque tour du jeu. 


#### Exploration du comportement des agents

Une partie non n√©gligeable du travail a √©t√© d'observer le comportements des agents et de modifier les informations auxquelles ils avaient acc√®s, leur actions possibles et leur prompt jusqu'√† obtenir une version satisfaisante. Mon objectif principal √©tait de leur faire adopter un comportement coh√©rent dans lequel ils partagerait des informations. Plus pr√©cis√©ment, je voulais qu'ils interagissent entre eux et s'entraident pour atteindre un objectif commun. Sachant que chacun d'entre eux ne peut voir qu'une partie du champ de bataille, vont-ils √™tre capable de se partager des informations et de coordonner leurs actions ?

Au d√©part, j'ai r√©alis√© de nombreux tests avec [GPT-3.5-turbo](https://fr.wikipedia.org/wiki/GPT-3), mais il √©tait difficile d'obtenir un prompt qui permettait d'obtenir √† coup s√ªr le r√©sultat dans un certain format. C'est une pr√©occupation importante pour un informaticien, car le format de sortie doit √™tre pr√©visible et coh√©rent pour que le code puisse interagir correctement avec lui.

> ‚ÑπÔ∏è **Update**
>
> Depuis la r√©daction de cet article, OpenAI a publi√© une [mise √† jour](https://openai.com/blog/function-calling-and-other-api-updates) de GPT-3.5 et GPT-4 permettant de la g√©n√©ration d'arguments pour des l'appels de fonction.
> Bien que non test√©e pour ce projet, cette fonctionnalit√© devrait r√©soudre ce dernier probl√®me permettre l'utilisation de GPT-3.5. 
> Cependant, il reste √† noter que GPT-4 est plus performant que GPT-3.5 pour de la logique et de la strat√©gie. GPT-4 produit donc de meilleurs agents.

Apr√®s de nombreux tests avec diff√©rents prompts, j'ai r√©ussi √† obtenir un comportement int√©ressant. Les agents communiquent avec leurs co√©quipiers pour coordonner leurs attaques ou partager des informations, malgr√© le co√ªt associ√© √† la communication. Elles prennent en compte les messages re√ßus de leurs camarades lors de leur tour de jeu, ce qui montre une v√©ritable coop√©ration entre elles.

Cependant, j'ai rencontr√© quelques difficult√©s. Au d√©but, les agents ne choisissaient pas de parler spontan√©ment. J'ai d√ª modifier le prompt pour les encourager √† le faire. C'est assez fascinant de voir comment le comportement d'un agent peut √™tre manipul√© simplement en modifiant du texte en langage naturel.

Il y a cependant des limites √† ce que nous pouvons accomplir. Les informations que les agents re√ßoivent sont limit√©es par la fa√ßon dont le jeu est impl√©ment√©. De plus, le prompt et la description du jeu qu'il contient limitent √©galement leur comportement. Trouver les instructions claires et concises qui auront le plus grand impact est un d√©fi en soi.

> üìù **Le prompt** 
>
> You're a helpful assistant who tells me the next immediate action to take in a turn-based strategy game with timeline. Your ultimate goal is to kill all enemy agents or destroy the enemy target, and not to die.
> 
> Those are some tips for the game:
> 1/ The map is composed of cells on an orthogonal grid. Each cell can be occupied only by one agent, target or obstacle.
> 2/ The center of the map is [0, 0].
> 3/ An attack reduces the life points of the target by 25.
> 4/ If you can see an agent, he can see you too.
> 5/ An enemy agent with low life can still attack you.
> 6/ Every agent has 3 actions per turn.
> 7/ Each move can be from 1 to 3 cells. The more cell you move, the faster you are, but the less you can see.
> 8/ Do not worry about obstacles or distances. You can make a clear attack on every enemy you see.
> 
> I'm going to give you the following information:
> Messages: sent by friends
> Historic: previous thoughts and actions you made
> Last Positions Seen: last positions of friends and enemies that you saw
> Your position: [x, y]
> Your life points: 100 max
> Friends: visible
> Enemy: visible
> Friendly target: visible
> Enemy target: visible
> Obstacles: visible
> Actions Left: number of actions left to perform this turn
> Possible Actions: you have to choose one of them
> 
> You must follow the following criteria:
> 1/ You must act as a strategic warlord and make the best decision for the mission.
> 2/ Please be very clear about your concerns and the reasons for your actions.
> 3/ The next action must be in the list of possible actions. Any action not included will be punished. Do not choose more than one action. Do not mention anything else than the chosen action.
> 5/ When you choose the action "SPEAK [x, y]", you must also include the message you want to send. This should follow a specific format: "SPEAK [x, y] The message you want to send.". The message must be less than 50 words.
> 6/ Please, share enemy positions with your friends if you think they do not see it according to their location. Do not share them your movements or location. Do not speak twice in a same turn to the same friend.
> 7/ Please answer to your friends when they ask you informations. But do not expect any answer or action from them until your next turn.
> 8/ Please, move intelliently. Use the coordinates of the cell to determine which cell is the best to move to. Do not go back on previous cells.
> 
> You should only respond in the format as described below:
> RESPONSE FORMAT:
> THOUGHTS: Based on the information I listed above, in 50 words, do reasoning about what the next task should be.
> ACTION: The next action.
> 
> Here's an example response:
> THOUGHTS: The enemy target is in my sight, I should attack it.
> ACTION: ATTACK [3, -1]




#### Perspectives et applications futures

Le projet "BattleFieldAgents" ouvre la voie √† de nombreuses possibilit√©s de recherche et d'application. L'une des perspectives les plus int√©ressantes selon moi est l'am√©lioration de ces agents via apprentissage par renforcement d'un [LLM](https://fr.wikipedia.org/wiki/Grand_mod√®le_de_langage) "miniature". Il existe aujourd'hui de nombreux mod√®le Open-Source de LLM, comme [GPT-2](https://en.wikipedia.org/wiki/GPT-2), [LLama](https://en.wikipedia.org/wiki/LLaMA) ou [Falcon](https://huggingface.co/tiiuae/falcon-40b). Il serait int√©ressant de voir si ces mod√®le - bien plus petits et moins performants que GPT-4 - peuvent √™tre finetun√© sur cette t√¢che sp√©cifique, et s'il peuvent √™tre utilis√© comme base pour l'entrainement par renforcement d'agent autonome. 

Ceci permettrait de remplacer GPT-4 qui pr√©sente trois d√©saventages majeurs : 
- Il est tr√®s co√ªteux. Chaque action co√ªte entre 0.01$ - 0.02$.
- C'est un mod√®le ferm√©. Nous ne connaissont pas les donn√©es sur lesquels il s'est entrain√© et ses biais.
- Nous ne pouvons pas le modifier et l'am√©liorer.
D'ailleurs, si le fine-tuning d'un [LLM](https://fr.wikipedia.org/wiki/Grand_mod√®le_de_langage) vous int√©resse, je vous invite √† lire [**GPTJ-OVERTON : le finetuning d'un LLM Politique**](/gptj-overton/).

Aussi, bien que le prompt actuel permette un comportement int√©ressant, il est loin d'√™tre parfait. Des recherches suppl√©mentaires pourraient √™tre men√©es pour am√©liorer le prompt et obtenir un comportement plus complexe et strat√©gique de la part des agents. 

Une autre possibilit√© est l'explicabilit√©s des d√©cisions des agents et de leur raisonnement. Nous pouvons imaginer entrenenir des discussions avec un agent tout au long de l'exp√©rience pour mieux comprendre ses d√©cisions et son raisonnement, ou m√™me pour lui donner des conseils sur la fa√ßon de se comporter dans une situation.

En outre, le projet pourrait √™tre √©tendu pour inclure plus d'agents, ou pour permettre aux agents d'avoir des "personnalit√©s" diff√©rentes bas√©es sur diff√©rents prompts. Cela pourrait conduire √† des dynamiques de jeu plus int√©ressantes et plus vari√©es.

Enfin, le projet pourrait √™tre utilis√© comme un outil d'apprentissage pour ceux qui s'int√©ressent √† l'IA et aux jeux vid√©o. En modifiant le code et en exp√©rimentant avec diff√©rents prompts, les utilisateurs peuvent en apprendre davantage sur le fonctionnement de [GPT-4](https://openai.com/gpt-4) et sur la mani√®re dont l'IA peut √™tre utilis√©e dans les jeux vid√©o, et en g√©n√©ral.


#### Conclusion

En utilisant [GPT-4](https://openai.com/gpt-4) pour contr√¥ler les agents dans un jeu de strat√©gie, **BattleFieldAgents** offre une nouvelle perspective de recherche sur les probl√®mes multi-agents et illuste bien le potentiel des [LLMs](https://fr.wikipedia.org/wiki/Grand_mod√®le_de_langage) dans de tels contextes. Bien qu'il reste encore beaucoup √† faire pour am√©liorer le comportement des agents et pour explorer d'autres applications possibles, **BattleFieldAgents** est un POC prometteur pour l'utilisation des [LLMs](https://fr.wikipedia.org/wiki/Grand_mod√®le_de_langage)s- pour le d√©veloppement d'agent intelligents capable de fournir des explications en langage naturelle de leurs d√©cisions et de leurs raisonnements.

##### Yannis Bendi-Ouis